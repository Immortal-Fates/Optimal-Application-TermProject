% References for DDP dynamic micro-batch scheduling project

@misc{PyTorchDDP,
  title        = {DistributedDataParallel â€” PyTorch Documentation},
  author       = {{PyTorch Team}},
  year         = {2024},
  howpublished = {\url{https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html}},
  note         = {Accessed: 2025-12-25}
}

@misc{HFDatasets,
  title        = {Hugging Face Datasets Documentation},
  author       = {{Hugging Face}},
  year         = {2024},
  howpublished = {\url{https://huggingface.co/docs/datasets}},
  note         = {Accessed: 2025-12-25}
}

@misc{HFTransformers,
  title        = {Transformers Documentation},
  author       = {{Hugging Face}},
  year         = {2024},
  howpublished = {\url{https://huggingface.co/docs/transformers}},
  note         = {Accessed: 2025-12-25}
}

@misc{GLUEBenchmark,
  title        = {GLUE: A Multi-Task Benchmark and Analysis Platform},
  author       = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  year         = {2018},
  howpublished = {\url{https://gluebenchmark.com/}},
  note         = {Accessed: 2025-12-25}
}

@misc{DistilBERT,
  title        = {DistilBERT: a distilled version of BERT},
  author       = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  year         = {2019},
  howpublished = {\url{https://arxiv.org/abs/1910.01108}},
  note         = {Accessed: 2025-12-25}
}

@misc{Vaswani2017,
  title        = {Attention Is All You Need},
  author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year         = {2017},
  howpublished = {\url{https://arxiv.org/abs/1706.03762}},
  note         = {Accessed: 2025-12-25}
}
